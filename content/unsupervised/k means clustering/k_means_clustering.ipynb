{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means Clustering is an unsupervised learning algorithm that solves clustering problems in machine learning or data science. In this topic, we will learn what is K-means clustering algorithm.\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/k-means-clustering1.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into algorithms, let’s first understand clustering,\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/k-means-clustering2.png\" width=800 />\n",
    "</div>\n",
    "\n",
    "- Clustering is a technique used in the K-means algorithm. In this algorithm, clustering refers to grouping similar data points based on their characteristics or features.\n",
    "- The goal of clustering is to partition a set of data points into distinct clusters, where each cluster consists of data points that are more similar than those in other clusters.\n",
    "- Clustering: grouping data based on similarity patterns based on distance\n",
    "- The goal is to group similar instances into clusters. Clustering is an excellent tool for data analysis, customer segmentation, recommender systems, search engines, image segmentation, semi-supervised learning, dimensionality reduction, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Mean Algorithm:\n",
    "\n",
    "- K means comes under Unsupervised learning and is also called clustering algorithm.\n",
    "- K mean is a clustering algorithm that is used to classify unlabeled data into groups/clusters based on similarity.\n",
    "- Here K defines the number of pre-defined clusters that need to be created in the process if K=2, there will be two clusters, and for K=3, there will be three clusters, and so on.\n",
    "- “It is an iterative algorithm that divides the unlabeled dataset into k different clusters in such a way that each dataset belongs to only one group that has similar properties.”\n",
    "- It allows us to cluster the data into different groups and is a convenient way to discover the categories of groups in the unlabeled dataset on its own without the need for any training.\n",
    "- It is a centroid-based algorithm, where each cluster is associated with a centroid. The main aim of this algorithm is to minimize the sum of distances between the data point and their corresponding clusters.\n",
    "- K-means then tries to determine different k-points called centroids, which are at the centre (least cumulative distance) from other points of the same class, but further away from points of another class.\n",
    "- The algorithm takes the unlabeled dataset as input, divides the dataset into k-number of clusters, and repeats the process until it does not find the best clusters. The value of k should be predetermined in this algorithm.\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/centroid.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim of the K-Mean Algorithm:\n",
    "The k-means clustering algorithm mainly performs two tasks:\n",
    "\n",
    "- Determines the best value for K centre points or centroids by an iterative process.\n",
    "- Assigns each data point to its closest K-center. Those data points which are near to the particular K-center, create a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How K-Mean Algorithm Works:\n",
    "\n",
    "1. Plot Data\n",
    "2. Select the number K to decide the number of clusters.\n",
    "3. Select random K points or centroids. (It can be other from the input dataset).\n",
    "4. Assign each data point to their closest centroid, which will form the predefined K clusters.\n",
    "5. Repeat the fourth step, which means reassigning each data point to the new closest centroid of each cluster.\n",
    "\n",
    "Until you get a clearer cluster means no overlapping.\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/clustering-steps.png\" width=800 />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will understand each figure one by one.\n",
    "\n",
    "- Figure 1 shows the representation of data from two different items. the first item has shown in blue colour and the second item has shown in red colour. Here I am choosing the value of K randomly as 2. There are different methods by which we can choose the right k values.\n",
    "- In Figure 2, Join the two selected points. Now to find out the centroid, we will draw a perpendicular line to that line. The points will move to their centroid. If you will notice there, then you will see that some of the red points are now moved to the blue points. Now, these points belong to the group of blue colour items.\n",
    "- The same process will continue in Figure 3. We will join the two points and draw a perpendicular line to that and find out the centroid. Now the two points will move to its centroid and again some of the red points get converted to blue points.\n",
    "- The same process is happening in Figure 4. This process will be continued until and unless we get two completely different clusters of these groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main points:\n",
    "\n",
    "- Intercluster distance should be high: The distance between observations in two clusters should be High.\n",
    "- Intracluster Distance should be Very Less: The distance of observation within the cluster should be very less.\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/intracluster-intercluster.png\" width=800 />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Distance:\n",
    "\n",
    "- Euclidean Distance Measure:\n",
    "\n",
    "The most common case is determining the distance between two points. If we have point P and point Q, the Euclidean distance is an ordinary straight line. It is the distance between the two points in Euclidean space.\n",
    "\n",
    "The formula for the distance between two points is shown below:\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/euclidean-distance.png\" width=400 />\n",
    "</div>\n",
    "\n",
    "- Manhattan Distance Measure:\n",
    "\n",
    "The Manhattan distance is the simple sum of the horizontal and vertical components or the distance between two points measured along axes at right angles.\n",
    "\n",
    "The formula is shown below:\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/manhattan-distance.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to evaluate K-Mean Model?\n",
    "\n",
    "- Silhouette Coefficient:\n",
    "\n",
    "Silhouette Coefficient or silhouette score is a metric used to calculate the goodness of a clustering technique. Its value ranges from -1 to 1.\n",
    "\n",
    "1: Means clusters are well apart from each other and clearly distinguished.\n",
    "\n",
    "0: Means clusters are indifferent, or we can say that the distance between clusters is not significant.\n",
    "\n",
    "- 1: Means clusters are assigned in the wrong way.\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/k-means-clustering3.png\" width=800 />\n",
    "</div>\n",
    "\n",
    "**Important Points:**\n",
    "\n",
    "- It will use a Distance measure.\n",
    "- Scaling is very important\n",
    "- Handling outliers is also Important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to select the optimal value for k?\n",
    "\n",
    "- Elbow Method:\n",
    "\n",
    "The Elbow method is one of the most popular ways to find the optimal number of clusters. This method uses the concept of WCSS value. WCSS stands for Within Cluster Sum of Squares, which defines the total variations within a cluster.\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/wcss.png\" width=600 />\n",
    "</div>\n",
    "\n",
    "How does it work?\n",
    "\n",
    "- Start with some k\n",
    "\n",
    "k=[2,3,4,5,6,…10]\n",
    "\n",
    "- If k=2 apply k-mean\n",
    "- It will find WCSS\n",
    "- Then step repeat for different k values\n",
    "- Plot a graph of k versus WCSS.\n",
    "- Choose the k value after which the WCSS value is constant.\n",
    "\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/elbow-method.png\" width=700 />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-mean Algorithm Overview:\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "<img src=\"images/overview.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources for this content:\n",
    "\n",
    "<a href=\"https://medium.com/@dishantkharkar9/k-means-clustering-algorithm-ce4fbcac8fb0\">K-Means Clustering Algorithm.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
